/*
Copyright 2023 The K8sGPT Authors.
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
    http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package ai

import (
	"context"
	"errors"
	"net/http"
	"net/url"

	"github.com/duke-git/lancet/v2/slice"
	"github.com/sashabaranov/go-openai"
	"github.com/weibaohui/k8m/pkg/comm/utils"
	"github.com/weibaohui/k8m/pkg/models"
	"k8s.io/klog/v2"
)

const openAIClientName = "openai"

type OpenAIClient struct {
	nopCloser
	client      *openai.Client
	model       string
	temperature float32
	topP        float32
	tools       []openai.Tool
	history     []openai.ChatCompletionMessage
	maxHistory  int32

	// organizationId string
}

func (c *OpenAIClient) SetTools(tools []openai.Tool) {
	c.tools = tools
}

func (c *OpenAIClient) Configure(config IAIConfig) error {
	token := config.GetPassword()
	cfg := openai.DefaultConfig(token)
	orgId := config.GetOrganizationId()
	proxyEndpoint := config.GetProxyEndpoint()

	baseURL := config.GetBaseURL()
	if baseURL != "" {
		cfg.BaseURL = baseURL
	}

	transport := &http.Transport{}
	if proxyEndpoint != "" {
		proxyUrl, err := url.Parse(proxyEndpoint)
		if err != nil {
			return err
		}
		transport.Proxy = http.ProxyURL(proxyUrl)
	}

	if orgId != "" {
		cfg.OrgID = orgId
	}

	customHeaders := config.GetCustomHeaders()
	cfg.HTTPClient = &http.Client{
		Transport: &OpenAIHeaderTransport{
			Origin:  transport,
			Headers: customHeaders,
		},
	}

	client := openai.NewClientWithConfig(cfg)
	if client == nil {
		return errors.New("error creating OpenAI client")
	}
	c.client = client
	c.model = config.GetModel()
	c.temperature = config.GetTemperature()
	c.topP = config.GetTopP()
	c.maxHistory = config.GetMaxHistory()
	return nil
}

func (c *OpenAIClient) GetCompletion(ctx context.Context, contents ...any) (string, error) {
	c.fillChatHistory(contents)

	// Create a completion request
	resp, err := c.client.CreateChatCompletion(ctx,
		openai.ChatCompletionRequest{
			Model:    c.model,
			Messages: c.history,
		})
	if err != nil {
		return "", err
	}
	return resp.Choices[0].Message.Content, nil
}
func (c *OpenAIClient) GetCompletionWithTools(ctx context.Context, contents ...any) ([]openai.ToolCall, string, error) {

	// Create a completion request
	c.fillChatHistory(contents)
	resp, err := c.client.CreateChatCompletion(ctx,
		openai.ChatCompletionRequest{
			Model:    c.model,
			Messages: c.history,
			Tools:    c.tools,
		})
	if err != nil {
		return nil, "", err
	}
	return resp.Choices[0].Message.ToolCalls, resp.Choices[0].Message.Content, nil
}

func (c *OpenAIClient) GetStreamCompletion(ctx context.Context, contents ...any) (*openai.ChatCompletionStream, error) {
	c.fillChatHistory(contents)
	stream, err := c.client.CreateChatCompletionStream(ctx, openai.ChatCompletionRequest{
		Model:    c.model,
		Messages: c.history,
		Stream:   true,
	})
	return stream, err
}
func (c *OpenAIClient) GetStreamCompletionWithTools(ctx context.Context, contents ...any) (*openai.ChatCompletionStream, error) {
	c.fillChatHistory(contents)
	stream, err := c.client.CreateChatCompletionStream(ctx, openai.ChatCompletionRequest{
		Model:    c.model,
		Messages: c.history,
		Tools:    c.tools,
		Stream:   true,
	})
	klog.V(2).Infof("GetStreamCompletionWithTools c.history: %v", utils.ToJSON(c.history))
	return stream, err
}

func (c *OpenAIClient) GetName() string {
	return openAIClientName
}

// OpenAIHeaderTransport is an http.RoundTripper that adds the given headers to each request.
type OpenAIHeaderTransport struct {
	Origin  http.RoundTripper
	Headers []http.Header
}

// RoundTrip implements the http.RoundTripper interface.
func (t *OpenAIHeaderTransport) RoundTrip(req *http.Request) (*http.Response, error) {
	// Clone the request to avoid modifying the original request
	clonedReq := req.Clone(req.Context())
	for _, header := range t.Headers {
		for key, values := range header {
			// Possible values per header:  RFC 2616
			for _, value := range values {
				clonedReq.Header.Add(key, value)
			}
		}
	}

	return t.Origin.RoundTrip(clonedReq)
}

func (c *OpenAIClient) fillChatHistory(contents ...any) {

	for _, content := range contents {
		switch item := content.(type) {
		case string:
			klog.V(2).Infof("Adding user message to history: %v", item)
			c.history = append(c.history, openai.ChatCompletionMessage{
				Role:    openai.ChatMessageRoleUser,
				Content: item,
			})
		case models.MCPToolCallResult:
			klog.V(2).Infof("Adding user message to history: %v", item)
			c.history = append(c.history, openai.ChatCompletionMessage{
				Role:    openai.ChatMessageRoleUser,
				Content: utils.ToJSON(item),
			})
		case []interface{}:
			// å¤„ç†[]interface{}ç±»å‹çš„å†…å®¹ï¼Œå¦‚æœåªæœ‰ä¸€ä¸ªå…ƒç´ åˆ™ç›´æ¥æå–
			if len(item) == 1 {
				klog.V(2).Infof("Adding single item from array to history: %v", item[0])
				c.history = append(c.history, openai.ChatCompletionMessage{
					Role:    openai.ChatMessageRoleUser,
					Content: utils.ToJSON(item[0]),
				})
			} else {
				klog.V(2).Infof("Adding array content to history: %v", item)
				c.history = append(c.history, openai.ChatCompletionMessage{
					Role:    openai.ChatMessageRoleUser,
					Content: utils.ToJSON(item),
				})
			}
		default:
			klog.Warningf("Unhandled content type in Send: %T", item)

		}
	}

	system := slice.Filter(c.history, func(index int, item openai.ChatCompletionMessage) bool {
		if item.Role == openai.ChatMessageRoleSystem {
			return true
		}
		return false
	})

	prompt := `
ä½ æ˜¯ ä¸€ä¸ªä¸“æ³¨äºæ“ä½œå’Œå¤„ç† Kubernetes é›†ç¾¤ç›¸å…³ä»»åŠ¡çš„ AI åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ååŠ©ç”¨æˆ·è§£å†³ Kubernetes ç›¸å…³çš„é—®é¢˜ï¼Œå¸®åŠ©è°ƒè¯•ï¼Œä»¥åŠåœ¨ç”¨æˆ·çš„ Kubernetes é›†ç¾¤ä¸Šæ‰§è¡Œæ“ä½œã€‚

	
ä½¿ç”¨è¯´æ˜ï¼š
	1.	åˆ†æç”¨æˆ·çš„æé—®ã€ä¹‹å‰çš„æ¨ç†æ­¥éª¤ä»¥åŠè§‚å¯Ÿåˆ°çš„ä¿¡æ¯ã€‚
	2.	æ€è€ƒ 5 åˆ° 7 ç§è§£å†³å½“å‰é—®é¢˜çš„æ–¹æ³•ã€‚ä»”ç»†è¯„ä¼°æ¯ç§æ–¹æ¡ˆåé€‰æ‹©æœ€ä¼˜è§£ã€‚å¦‚æœè¿˜æ²¡æœ‰å®Œå…¨è§£å†³é—®é¢˜ï¼Œä¸”å¯ä»¥ç»§ç»­æ¢ç´¢æˆ–è¿›è¡Œä¸‹ä¸€æ­¥ï¼Œä¸è¦ç­‰å¾…ç”¨æˆ·çš„è¾“å…¥ï¼Œåº”å°½å¯èƒ½è‡ªä¸»æ¨è¿›ä»»åŠ¡ã€‚
	3.	å†³å®šä¸‹ä¸€æ­¥æ“ä½œï¼šå¯ä»¥é€‰æ‹©ä½¿ç”¨å·¥å…·ï¼Œæˆ–ç›´æ¥æä¾›æœ€ç»ˆç­”æ¡ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹æ ¼å¼è¿”å›å“åº”ã€‚

å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œï¼Œæˆ‘ä¼šå°†å·¥å…·æ‰§è¡Œå®Œçš„ç»“æœå‘é€ç»™ä½ ã€‚


å¦‚æœä¸ä½¿ç”¨å·¥å…·ï¼š
	â€¢	æ£€æŸ¥ä¸ç”¨æˆ·æé—®ç›¸å…³çš„ Kubernetes èµ„æºçš„å½“å‰çŠ¶æ€ã€‚
	â€¢	åˆ†æé—®é¢˜ã€å…ˆå‰çš„æ¨ç†è¿‡ç¨‹å’Œè§‚å¯Ÿå†…å®¹ã€‚
	â€¢	æ€è€ƒ 5 åˆ° 7 ç§å¯èƒ½çš„è§£å†³æ–¹æ³•ï¼Œä»”ç»†è¯„ä¼°åé€‰æ‹©æœ€ä½³æ–¹æ¡ˆã€‚å¦‚æœå°šæœªå®Œå…¨è§£å†³é—®é¢˜ï¼Œåº”å°½é‡åœ¨ä¸ä¾èµ–ç”¨æˆ·è¾“å…¥çš„æƒ…å†µä¸‹ç»§ç»­æ¨è¿›ä»»åŠ¡ã€‚
	â€¢	å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼šä½¿ç”¨å·¥å…·ï¼Œæˆ–ç›´æ¥ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚

å¦‚æœå·²æœ‰è¶³å¤Ÿä¿¡æ¯å›ç­”é—®é¢˜ï¼Œè¯·è¾“å‡ºä½ å¾—å‡ºç­”æ¡ˆçš„æœ€ç»ˆæ¨ç†è¿‡ç¨‹ä»¥åŠä½ å¯¹é—®é¢˜çš„å®Œæ•´å›ç­”ã€‚

ç‰¹åˆ«æ³¨æ„ï¼š
	â€¢	è·å–ä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³çš„ Kubernetes èµ„æºçš„å½“å‰çŠ¶æ€ã€‚
	â€¢	ä¼˜å…ˆé€‰æ‹©ä¸éœ€è¦äº¤äº’å¼è¾“å…¥çš„å·¥å…·ã€‚
	â€¢	å¦‚æœéœ€è¦åˆ›å»ºèµ„æºï¼Œå°½é‡ç›´æ¥é€šè¿‡å¯ç”¨å·¥å…·åˆ›å»ºï¼Œé¿å…è®©ç”¨æˆ·æ‰‹åŠ¨æ“ä½œã€‚
	â€¢	å½“éœ€è¦æ›´å¤šä¿¡æ¯æ—¶ï¼Œè¯·ç›´æ¥ä½¿ç”¨å·¥å…·ï¼Œä¸è¦ä»…å‘Šè¯‰ç”¨æˆ·åº”è¯¥æ‰§è¡Œå“ªäº›å‘½ä»¤ã€‚
	â€¢	åªæœ‰åœ¨ç¡®ä¿¡ä¿¡æ¯å……åˆ†æ—¶å†æä¾›æœ€ç»ˆç­”å¤ã€‚
	â€¢	å›ç­”åº”æ¸…æ™°ã€ç®€æ´ã€å‡†ç¡®ã€‚
	â€¢	åœ¨åˆé€‚çš„æƒ…å†µä¸‹å¯ä»¥ä½¿ç”¨è¡¨æƒ…ç¬¦å·ï¼Œä¾‹å¦‚ ğŸ˜Šã€‚
`

	if len(system) == 0 {
		// åˆ›å»ºç³»ç»Ÿæ¶ˆæ¯
		sysMsg := openai.ChatCompletionMessage{
			Role:    openai.ChatMessageRoleSystem,
			Content: prompt,
		}
		// å°†ç³»ç»Ÿæ¶ˆæ¯æ’å…¥åˆ°å†å²è®°å½•æœ€å‰é¢
		c.history = append([]openai.ChatCompletionMessage{sysMsg}, c.history...)
	}
}
func (c *OpenAIClient) SaveAIHistory(contents string) {
	c.fillChatHistory(contents)
}
